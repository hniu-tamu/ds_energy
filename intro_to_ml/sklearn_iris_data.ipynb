{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hniu-tamu/ds_energy/blob/main/intro_to_ml/sklearn_iris_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGEQoSCMInEf"
      },
      "source": [
        "# Machine Learning with scikit-learn\n",
        "Haoyu Niu, Texas A&M University\n",
        "\n",
        "Updated on Feb 20, 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnDhMPruInEg"
      },
      "source": [
        "We will explore the Iris Data set again with scikit-learn, which contains a clean copy of the Iris data set.\n",
        "<img src=\"https://github.com/jtao/dswebinar/blob/master/sklearn/session2/images/petal_sepal.jpg?raw=1\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUmgO1S3InEg"
      },
      "source": [
        "### Import modules, load the Iris data set, and prepare the data set for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKKDHn2tInEh"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgq66nDDInEj"
      },
      "outputs": [],
      "source": [
        "# load the data set\n",
        "iris = datasets.load_iris()\n",
        "n_samples, n_features = iris.data.shape\n",
        "print(iris.keys())\n",
        "print((n_samples, n_features))\n",
        "print(iris.data.shape)\n",
        "print(iris.target.shape)\n",
        "print(iris.target_names)\n",
        "print(iris.feature_names)\n",
        "X, y = iris.data, iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32jF_jVaNz4q"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                columns= iris['feature_names'] + ['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUEIjTe8Oeos"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STE8ST_1T0aF"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W0Zf-93PmbF"
      },
      "outputs": [],
      "source": [
        "#df = df.drop(['target'], axis=1)\n",
        "sns.pairplot(df, kind=\"scatter\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDHbMF-bT59M"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQcJvwv3VCEm"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr(), annot=True, fmt=\".3f\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U09z3qgCInEl"
      },
      "outputs": [],
      "source": [
        "#split the data into training and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7-GBXTgInEn"
      },
      "outputs": [],
      "source": [
        "# scale the train data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
        "y_combined = np.hstack((y_train, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrMU6UjAInEp"
      },
      "source": [
        "### Classification - Perceptron\n",
        "The Perceptron is another simple binary classification algorithm suitable for large scale learning. By default:\n",
        "\n",
        "It does not require a learning rate.\n",
        "It is not regularized (penalized).\n",
        "It updates its model only on mistakes.\n",
        "The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYN8ZWZOInEp",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
        "ppn.fit(X_train_std, y_train)\n",
        "y_pred = ppn.predict(X_test_std)\n",
        "print('Misclassfied samples: %d' % (y_test != y_pred).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj86cqF0InEr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print ('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryb3Y-4XInEt"
      },
      "source": [
        "### Classification - Supporting-vector classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmtvpYPyInEu"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_std, y_train)\n",
        "\n",
        "print('The accuracy of the svm classifier on training data is {:.2f} out of 1'.format(svm.score(X_train_std, y_train)))\n",
        "\n",
        "print('The accuracy of the svm classifier on test data is {:.2f} out of 1'.format(svm.score(X_test_std, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIA3xU-PInEv"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
        "knn.fit(X_train_std, y_train)\n",
        "\n",
        "print('The accuracy of the knn classifier is {:.2f} out of 1 on training data'.format(knn.score(X_train_std, y_train)))\n",
        "print('The accuracy of the knn classifier is {:.2f} out of 1 on test data'.format(knn.score(X_test_std, y_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "sklearn_iris_data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}